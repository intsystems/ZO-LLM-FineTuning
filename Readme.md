# # ZO LLM Fine-Tuning

**Author:** Grigory Evseev

**Consultant:** Andrey Veprikov  

**Expert:** Aleksander Beznosikov  

## Description of work 

This paper is devoted to the study of zero-order methods for the pre-training of Large Language Models. Two new methods are presented: ZO Jaguar SignSGD, ZO Jaguar Muon

# Дообучение LLM с помощью оптимизации нулевого порядка

**Автор:** Евсеев Григорий

**Консультант:** Веприков Андрей Сергеевич

**Эксперт:** Безносиков Александр Николаевич

## Описание работы 

Данная работа посвящана исследованию методов нулевого порядка для дообучения Больших Языковых моделей. Представлены два новых метода: ZO Jaguar SignSGD, ZO Jaguar Muon

